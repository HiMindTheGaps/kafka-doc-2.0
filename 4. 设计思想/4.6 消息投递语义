现在我们对 producer 以及 consumer 的工作原理已经有了一些了解，下面我们一起来探讨 Kafka 是如何在 producer 以及 consumer 之间保证消息投递语义的。很显然，Kafka 也可以保证多种消息投递语义：

- 至多一次：消息也许会丢失但是永远不会重复投递
- 至少一次：消息从不会丢失但是可能会重复投递
- 恰好一次：这正是使用者所期望的，每个消息只会被恰好投递一次，不多不少

需要注意的是，消息的投递语义可以分成两个问题讨论：消息可靠性在发布过程中如何保证以及在消费过程中如何保证。

很多消息系统都声称它们拥有「恰好一次」的投递语义，但是当读到细节时你会发现：这些大多数声称的内容其实是一种误导，比如说，它们并不会考虑如下一些极端情况：consumer 或者 producer 突然挂掉、多个 consumer 共同消费、写到磁盘的数据也可能会丢失等等。

Kafka 的语义都是直接了当的。在发布消息的流程中，Kafka 有一个这样的概念：消息被**提交**到日志中。一旦一条消息被**提交**了，那么只要这个消息对应的 partition 的任意一个副本所在的 broker 还存活，消息就不会丢失。已提交消息、存活的 partition 以及对于 Kafka 会尝试处理哪些失败场景这些概念会在下一节详细描述。就当前而言，我们可以先假设 broker 是完美且不会挂掉的，先去尝试理解 producer 以及 consumer 如何保证这个语义。如果某个 producer 在尝试发送一条消息时遇到了网络错误，那它无法确认这个错误到底是发生在消息被提交前还是提交后，这就像是向数据库中插入一条数据同时自动自增主键这类场景一样棘手。

在 0.11.0.0 版本之前，如果 producer 并没有成功收到标识消息被提交的 ack，那么它能做的事情只有重试。在这种情况下，它就提供了一种「至少一次」的投递语义，因为最初的那条消息如果确实是被成功提交了，那么这条消息就会在重发期间被写入日志两次。从 0.11.0.0 版本之后，Kafka 的 producer 支持幂等投递操作，这意味着重发并不会导致日志中出现重复消息。幂等操作的实现方式是：broker 给每一个 producer 都分配一个 ID，同时利用 producer 随每个消息一起发送的序列号对消息进行去重。也是从 0.11.0.0 版本开始，producer 支持了给多个 topic 发送消息期间使用一种类似事务的语义，所有的消息要么全部发送成功，要么全部失败。这个功能的主要使用场景就是多个 topic 之间需要保证「恰好一次」。

其实并不是所有的场景都需要保证这么强的语义。在那些对延迟敏感的场景，Kafka 允许使用者自定义它所需要的持久化级别。如果producer 确实有必要等着消息被提交的 ack，那么这整个过程可能会耗时 10ms。producer 也可以指定完全异步的发送或者说它希望仅仅等到 leader 落盘之后就算发送成功。

接下来我们从 consumer 的视角来看一下投递语义是如何被保证的。每个 partition 的所有副本都拥有完全一致的消息内容，同时每条消息的 offset 也是完全一致的，当前消费位点是由 consumer 来控制的。如果我们假设 consumer 永远不会挂掉，那么 consumer 完全可以在它自己的内存中存储消费位置。但是一旦某台 consumer 挂掉了，我们希望这个 partition 可以被其他 consumer 进程所接管，那么这个新的 consumer 进程需要有一种机制去找到挂掉的 consumer 所消费的位置继续消费。consumer 在消费消息过程中，对于消息的处理以及更新消费位点的时机一般有如下两种做法：

1. consumer 消费到消息，首先保存最新的消费位点，然后开始处理这条消息。这种处理方式存在这样一种可能：如果 consumer 在保存消费位置之后、消费处理完之前挂掉了，那么即使有一些已经被提交的消息还没有被旧的 consumer 所处理，接管的新的 consumer 进程仍然会从被提交的位点继续消费。这种处理方式就对应着「至多一次」语义，因为在这种情况下，consumer 挂掉是有可能导致消息未被处理的。
2. consumer 消费到消息，首先处理这条消息，处理完成之后才会提交消费位点。这种处理方式存在这样一种可能：如果 consumer 在消息处理完成之后、成功提交消息位点之前挂掉了，那么接管的那个新的 consumer 首先处理到的几条消息有可能已经被旧的 consumer 处理过。这种处理方式对应着「至少一次」的语义。但是许多场景下，消息都会带有一个主键，使得消息的处理是一种幂等操作。（即使同一个消息收到了两次，那么第二次也只是重写了一次它自己的副本而已）。

那么到底应该如何理解「恰好一次」语义（也就是正是你想要的东西）呢？假设一个应用从 Kafka 的一个 topic 消费数据然后写到 Kafka 的另一个 topic 中（就像 Kafka Stream 应用一样），我们可以将上面提到的在 0.11.0.0 版本之后的 producer 引入的事务性利用起来。我们将 consumer 的消费位点也写入到一个 topic 中，所以我们可以将提交 offset 的动作和将被处理完成的消息写到输出 topic 这个动作置于同一个事务中。如果这个事务回滚了，那么 consumer 的消费位点会回退到旧值，写到输出 topic 中的数据对于其他的 consumer 也是不可见的，不过这取决于它的隔离级别。如果隔离级别是默认的“读未提交”，即使有一些消息属于回滚的事务的一部分，他们对于 consumer 而言也是可见的；但是在“读已提交”的隔离级别下，consumer 只会消费到那些已经被提交了的事务中的消息（当然对于不在事务中的消息它们也是可以消费的）。

当向外部系统写入时，限制在于如何协调 consumer 的消费位点以及输出内容的实际存储。比较经典的一种实现方式就是在存储 consumer 消费位点以及存储 consumer 的输出之间引入两阶段提交。但实际上有更简单的处理方式，通常我们会让 consumer 将消费位点数据也存到和输出数据相同系统上。这样做更好的原因是 consumer 所写的外部系统通常来说可能并没有两阶段提交（事务）这个概念。举个例子来说，假如 [Kafka Connect](https://kafka.apache.org/documentation/#connect) 中的一个 connector 将它的 offset 和输出的数据一同存到 HDFS 上，这样就可以保证数据和偏移量要么同时更新要么同时不更新。对于那些要求有很强语义的系统但是消息本身又不具备主键导致没法去重这种场景，我们建议使用上述处理模式。

综上，Kafka 在 [Kafka Streams](https://kafka.apache.org/documentation/streams/) 中有效地提供了「恰好一次」的投递语义，同时也可以依赖事务性的 producer/consumer 在多个 Kafka topic 之间保证「恰好一次」地传输处理数据。如果想要「恰好一次」地向其他系统中投递数据，那么一般会要求和其他系统进行协调，Kafka 提供了一个 offset 机制会使得这种协调方式变得更简单（可以参考 [Kafka Connect](https://kafka.apache.org/documentation/#connect)）。除此之外，Kafka 默认是支持「至少一次」投递语义的，同时允许使用者自己去实现「至多一次」投递语义，这要求禁用 producer 端的重试机制同时 consumer 需要在处理消息之前 commit offset。