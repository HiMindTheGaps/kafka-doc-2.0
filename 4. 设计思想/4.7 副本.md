Kafka 支持对每个 topic 的每个 partition 在多个 broker 之间复制日志，日志的副本数支持可配置（使用者可以在 topic 级别配置这个副本数量）。这样一来，当集群中的一台 broker 发生故障，请求也可以自动转移到其他副本所在的 broker 上，也就是说在有实例故障的场景下 Kafka 整体服务依然可用。

其实很多其他消息系统也提供了这种多副本的机制，但是恕我直言（带有一定偏见），这些消息系统的多副本机制完全就是一种附加的特性，这些系统对这个特性的依赖不是很重，而且会带来大量的副作用：比如从节点完全是 inactive 的、吞吐量会收到极大的影响、人工配置复杂等等。Kafka 默认就支持多副本机制。实际上，Kafka 也支持非副本复制的 topic，但其实也就是一种多副本的一种特例，即副本数为 1。

副本的最小单元就是单 topic 的单 partition。在正常情况下，每个 partition 都有一个 leader 副本以及零个或者多个 follower 副本，包括 leader 在内的所有副本组成了这个 partition 的副本因子。所有的读写操作都是基于 leader 副本完成的，一般来说，一个集群中的 partition 的数量是远大于 broker 数量的，那所有的 leader 副本就可以均匀的分布在 broker 之间达到负载均衡。follower 副本上的日志文件和 leader 副本上的日志文件完全相同 —— offset 完全相同而且消息的顺序完全相同（当然，在任意时刻，leader 副本日志文件的末尾可能存在一些还未经同步的消息）。

follower 会像一个正常的 Kafka consumer 一样从 leader 上拉取消息，然后将它们追加到本地的日志文件上。这种拉数据的模式有一个很好的特性：follower 可以将即将要追加到日志文件中的消息很自然的聚合在一起。

和大部分分布式系统一样，Kafka 也需要对节点“存活”这个概念有一个明确的定义。在 Kafka 中，一个节点存活需要满足以下两个条件：

- 这个节点必须要维持和 Zookeeper 之间的 session（通过 Zookeeper 的心跳机制）
- 如果它是一个从节点，那么它必须复制 leader 上的数据而且不能落后太远

我们将满足上述两个条件的节点称之为“在同步中（in sync）”，这样可以避免使用“存活（alive）”或者“失败（failed）”这样模糊的概念。leader 会一直追踪这个“同步”节点列表（ISR），如果一个 follower 挂掉或者卡住了或者落后太多，leader 会将它从 ISR （in sync replica）列表中移除。卡住或者复制落后的界定是通过`replica.lag.time.max.ms`这个配置实现的。

在分布式系统这个领域中，我们一般只处理错误中的“失败/恢复”这种场景，也就是节点突然停止工作，然后过一会儿又可以恢复（甚至可能都没有意识到这个节点曾经挂掉过）。Kafka 也是一样，不会尝试去处理“拜占庭”式的错误 —— 节点会产生随机的或者恶意的响应（比如说由于 bug 或者犯规）。

到此为止，我们可以对消息被提交这个概念做一次更明确的定义：被提交代表该消息被写入到该 partition ISR 列表中所有节点的日志中。只有被提交的消息才会对 consumer 可见，这就意味着 consumer 无需担心它们此刻消费到的消息会因为 leader 挂掉而丢失。另一方面，producer 是可以自己选择在发送消息时要不要一直等到消息被提交，这取决于 producer 对于延时以及消息可靠性的取舍，这个选择是由 producer 端的一个参数 —— ack 来控制的。需要注意的是，每个 topic 都有一个参数用于设置 ISR 列表中的最小节点数，这个参数会在 producer 要求有 ack 的时候会被用到，代表着多少个副本写成功才可以返回 ack。如果对 ack 的要求不是很严格，那么即使 ISR 列表中的副本数低于这个参数的值（比如说，ISR 列表中的节点数只有 leader 一个），消息仍然可以被提交、被消费。

Kafka 所能保证的是：只要任何时间 ISR 列表中都有至少一个节点存活，那么被提交的消息就永远不会丢失。

Kafka 会在节点发生故障之后经过短暂的 failover 就可以保持可用状态，但是如果处于网络分区状态下就没法保证依然可用了。

## 可复制的日志：最小副本数、ISR、[状态机](https://en.wikipedia.org/wiki/State_machine_replication)

Kafka partition 的核心就是可复制的日志。可复制的日志就是分布式数据系统的基石，可以有很多实现方式。

可复制的日志抽象出基于一串有序数字（通常来说就是给日志条目标号 1,2,3）来实现顺序一致性的模型。实现这个模型有很多种方式，最简单也是效率最高的一种便是选出一个主节点用于给消息排序。只要主节点还存活，那么所有从节点只需要按照主节点上的消息顺序从主节点上拷贝数据即可。

当然如果主节点一直不宕机我们也没有必要设置从节点！一旦主节点发生故障，我们需要从从节点之间选出一个新的主节点，但是此时从节点可能同步数据落后很多甚至已经崩溃了，所以我们需要一种机制可以保证选出一个拥有最新数据的从节点。一个日志复制算法所需要提供的最基础保证就是一旦通知客户端消息已经被提交，那么即使主节点发生故障，新选出的主节点也必须拥有这条消息。这就需要我们进行权衡：如果想要拥有更多备选的主节点，那么主节点在决定消息被提交之前需要更待更多的从节点完成同步。

如果你确定了消息提交之前所必须完成同步的从节点数量以及选主节点时所需要比较的日志数量并可以保证这两个条件在选主的时候有重叠，那么这种选主的方式就称之为最小副本数（Quorum）。

对于上面提到的权衡的一种通用实现方式就是在决定是否提交消息以及如何选主的过程中使用「超过半数投票原则（majority vote）」。虽然 Kafka 并没有应用这种方式，但是我们还是来了解一下这种权衡是如何实现的。如果说我们有 2f+1 个副本，同时我们认为 f+1 个副本收到了一条消息，这条消息才会被认为被提交；同时，在选主的过程中，我们需要在至少 f+1 个副本当中选出一个消息最完整的副本作为新的主节点。那么，只要宕机的副本数量不超过 f 个，那么新选出的主节点就一定可以保证拥有全部消息。因为在任意 f+1 个副本中，至少有一个副本包含所有已经提交的消息，这个副本的消息就是最全的，最终会被选出作为新的主节点。当然了，这当中还有很多细节需要处理（比如说如何精确地定义何为更完整的日志，如何在主节点宕机之后保证消息的连续性，如何修改副本集合中的服务节点等等），但是我们目前先忽略这些细节问题。

这种超过半数投票的方法有一个很大的优势就是：延时仅仅取决于最快的那个从节点。比如说副本数量是 3，那么提交消息的延时取决于更快的那个从节点而不是更慢的那个。

这种算法也有很多变种并形成了一个算法簇，包括 Zookeeper 的 [Zab](http://web.archive.org/web/20140602093727/http://www.stanford.edu/class/cs347/reading/zab.pdf)、[Raft](https://ramcloud.stanford.edu/wiki/download/attachments/11370504/raft.pdf)、以及 [Viewstamped Replication](http://pmg.csail.mit.edu/papers/vr-revisited.pdf) 等。到目前为止，我们了解到和 Kafka 的实际实现方式最为接近的算法是来自微软的 [PacificA](http://research.microsoft.com/apps/pubs/default.aspx?id=66814)。

这种超过半数投票算法的劣势就是一小部分副本宕机就会让你陷入到没有主节点可选的境地。为了能够容忍一个副本宕机，我们需要给每份数据做三份拷贝、为了能够容忍两个副本宕机，我们需要给每份数据做 5 份拷贝。根据我们的经验，在一个实际的系统中，仅仅能够容忍单副本宕机是远远不够的，但是将每个写操作都重复 5 次，同时要求有五倍的存储空间以及仅仅能达到 1/5 的吞吐量，这种缺陷对于大数据系统是无法接受的。可能这就是为什么 Quorum 算法更多出现在类似于 Zookeeper 这类主要存储集群共享元数据信息的系统之上，而不是更多用在数据存储为主的系统之中。举个例子，HDFS namenode 的高可用就是基于[超过半数算法](http://blog.cloudera.com/blog/2012/10/quorum-based-journaling-in-cdh4-1)实现的，但是这种算法并不会用于 HDFS 存储数据本身上。

## 不纯粹的主节点选举：万一他们都挂了该怎么办呢？

我们需要注意的是，Kafka 所保证的数据不丢是建立在每时每刻 ISR 列表中都至少有一个副本存活，如果说某个 partition 的所有副本都挂掉了，这个保证也就不存在了。

然而，实际上，一个系统在面对所有副本都挂掉了这种场景总得需要做些什么。如果你真的很不走运遇到了这种情况，确实很有必要去想一想在这种情况下会发生什么。下面提到了在这种情况下的两种行为：

1. 等待 ISR 列表中的某个副本恢复正常然后选举这个副本作为 leader（当然我们很希望这个副本上的数据不会丢失）
2. 选择第一个恢复的副本（不一定非要在 ISR 列表中）作为 leader 节点

上述两种行为其实就是在可用性以及数据一致性之间做取舍。如果说我们等着 ISR 列表中的副本重新上线，那么只要 ISR 里的所有副本都一直没有恢复，服务就会一直停留在不可用状态。如果 ISR 列表中的副本已经被销毁了或者数据丢失了，那么服务就相当于是永久的挂掉了，永远没法恢复可用状态。那么反过来说，假如一个不在 ISR 列表中的副本先恢复了同时我们允许它成为 leader，那么即使这个节点不会拥有这个 partition 上所有已经提交的消息，这个 partition 上的数据依然会以这个节点上的日志为准。从 0.11.0.0 版本开始，Kafka 默认选择第一种策略，倾向于等待一个一致性的副本恢复。不过如果你的使用场景更倾向于实时性而不是数据一致性，这种行为是可以通过配置`unclean.leader.election.enable`这个属性来修改的。

不只是 Kafka 存在这种两难境地，它存在于任何基于 Quorum 的分布式系统中。比如说在那些使用超过半数投票方案的系统中，如果大部分服务器遭受了永久性的故障，那么你必须选择失去 100% 的数据或者违反数据的一致性，将现有服务器上的内容作为新的数据基准。

## 可用性和数据可靠性的保证

当 producer 向 broker 写一条消息时，producer 可以通过设置 ack 的值（0, 1, -1）来控制它自己是否需要等待消息的响应。但是需要注意的是，“-1，也就是被全部的副本所响应”并不代表着这个 partition 的所有副本都已经收到这条消息了。默认情况下，当 producer 端设置 ack 为 all 的时候，只要 ISR 列表中的副本都收到了这条消息，ack 就会响应给 producer 了。举个例子，如果一个 topic 配置只有两个副本并且其中一个已经挂掉了（也即是说现在 ISR 列表中只有一个副本），那么即使 ack 设置为 all 写入也能成功。然而，如果仅存的这个副本后面也挂掉了，那么之前写入的消息就有可能丢失。尽管这样的机制保证了这个 partition 最大程度可用，但是对于那些更看重消息可靠性的场景而言，这种行为是不可取的。因此，我们提供了两个 topic 级别的配置可以用于在消息的可靠性以及服务可用性之间进行取舍。

1. 禁用掉 unclean leader election。如果所有的副本都挂了，那么这个 partition 就会进入不可用状态直到最近的一个 leader 重新变得可用。可以看出，这种方式宁可牺牲服务的可用性，也不能允许出现数据丢失的风险。关于 Unclean Leader Election 的说明可以参看上一小节。
2. 指定一个最小 ISR 列表的副本数量。只有当 ISR 列表的副本数超过了这个预设的最小值，这个 partition 才是可写状态，这样就可以防止仅仅将消息写入单一的副本然后这个副本又突然挂掉这种场景造成的数据丢失问题的出现。这个配置只有在 producer 端将 ack 设置为 all 的时候生效，并且保证至少有这么多的副本数复制成功才会给 producer 回复 ack。这个配置就相当于在数据一致性和可用性之前提供了一种取舍的能力。将这个配置值设置得很高可以保证更好的数据一致性，因为消息可以保证被写入到更多的副本中，进而降低数据丢失的概率；然而，这样做却降低了服务的可用性，因为一旦 ISR 列表中的副本数量低于这个阈值，partition 就变得不可写了。

## 副本管理

上面关于可复制副本的讨论都是基于单一日志而言，比如说单 topic 单 partition。然而，一个 kafka 集群通常是需要管理成百上千个 partition 的。我们尝试通过轮询的方式在集群内部平衡 partition 的分布，防止一个数据量很大的 topic 的所有 partition 都压到一小部分 broker 节点上。同样我们也会尝试平衡每个节点上的 leader 副本数量，这样带来的好处就是所有 partition 的 leader 副本在整个集群上分布都很均衡。

对于 leader 选举过程的优化也很有必要，因为这期间是 Kafka 很长一段不可用时间。关于 leader 选举的一个简单实现是可能会在一个节点挂掉之后，为这个节点上的所有 partition 都依次执行一遍 leader 选举过程。Kafka 并不是这样，Kafka 会选取一个 broker 作为 controller，这个 controller 会检测到出问题的 broker，并负责修改故障 broker 上受影响的所有 partition 的 leader 副本。这样带来的好处就是我们可以将很多 leader 副本变化的通知聚合到一起，进而使得 leader 选举过程即使在大量 partition 的场景下显得更加轻量也更快。如果说 controller 节点挂掉了，那么会从还在存活的 broker 中选出一个作为新的 controller。