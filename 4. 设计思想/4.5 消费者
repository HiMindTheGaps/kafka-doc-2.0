Kafka consumer 的工作模式是向它所订阅的 partition 的 leader 所在的 broker 发送 fecth 请求。consumer 会在请求中携带它想要拉取的数据在日志中的 offset，接下来会收到从那个 offset 位置开始的一大块数据。这样看起来，consumer 拥有对这个 offset 值的决定权，所以如果有需要的话，它可以回退重新消费一些历史数据。

## 推 or 拉

关于 consumer 我们需要考虑的第一个问题是：数据的流转方式到底应该是 consumer 从 broker 上主动拉取数据还是 broker 将数据主动推给 consumer。在这方面，Kafka 借鉴了大多数消息系统所采用的较为传统的设计模式，也就是：producer 将数据推给 broker，然后 consumer 又主动从 broker 中将数据拉过来。一些以日志为基石的系统，比如说 Scribe 以及 Apache Flume 等，都是应用了一种与之不同的、以推为主的设计模式，也就是说数据是由服务端主动推给下游消费端的，这两种方式各有优劣。然而，以推为主的消息系统很难处理 consumer 消费速度不同的情况，因为在这种数据流转模式下，数据的传输速度是由 broker 来控制的。对于 consumer 而言，目标就是尽可能地以最高速度来消费数据。但是实际上，如果 consumer 的消费速度落后于消息的生产速度，consumer 很有可能会被积压的消息压垮（实际上这就是一种`denial of service attack`）。但是以拉为主的系统在这种场景下就可以做得更好：consumer 仅仅是消费落后，它可以在后面慢慢追赶。不过这个问题也可以通过某种 backoff 协议来缓解，consumer 可以通过这种协议来表示它自己已经不堪重负，但是基于特殊协议来想让数据的传输速度充分利用（但不是过度利用）consumer 的性能远比想象中复杂得多。之前以这种方式建立消息系统的尝试让我们采用了更加传统的拉模型。

基于拉的系统的另一个优势就是它会积极地批量发送数据给 consumer。一个基于推的系统推消息的时机是要么当消息到来时立即发送出去，要么攒更多的消息然后一次性都发出去，但是这样其实对于下游 consumer 是否能够立即处理都是未知的。如果倾向于低延时，那么就会选择每次只发送单条消息，这是一种性能浪费的行为，因为数据最终还是会在 socket 缓冲之后一起传输。基于拉的模型解决了这个问题，因为 consumer 永远都是主动拉取它正在处理之后的所有可用消息（或者是一个可配置的固定长度的消息集合）。所以对于系统整体而言，这种方式实现了最佳的批量处理方式，同时没有引入额外的延时。

一种简单的拉模型的缺点就是如果 broker 此刻没有数据，那么 consumer 就会不停地轮询， 一直忙轮询等待新数据的到来。为了避免上述情况发生，我们在拉请求中加了一个参数，这个参数允许 consumer 被阻塞在一个”长轮询“之中，直到有数据到来（也可以等到有足够多数据到来确保触发一次更大的数据传输）。

你可能会想到一些其他的消息流转设计方式，比如说端到端的拉模型。producer 会将数据写到本地的日志中，然后 broker 主动从producer 的本地日志中拉到数据，consumer 也是主动从 broker 中拉到数据。类似的 「store-and-forward」 producer 的概念经常被提起，这确实很值得我们研究，但是我们认为这种模型对于 Kafka 的目标场景（有成百上千的 producer）并不合适。以往运行大规模的持久化数据系统的经验告诉我们，一个在很多应用之间并且包含了上千块磁盘的系统实际上并不会有多好的可靠性提升，反而对于运维而言是一种灾难。而且实际上我们发现，即使不使用 producer 持久化的方式，一个大规模的消息系统仍然可以保证很强的 SLA。

## 消费位置

我们惊奇地发现，对于一个消息系统而言，如何记录哪些消息已经被消费过是一个很关键的影响性能的因素。

大多数的消息系统都是在 broker 端记录哪些消息已经被消费过，大概流程就是：当一个消息被发送给 consumer，broker 要么直接本地记录下这个消息已经被消费过，要么会等着 consumer 返回一个 ack，这是一个很自然的选择，而且实际上对于一个单机服务器而言，也很难想得出还有哪里记录这个状态更优。更何况，在很多消息系统中，持久化消息的数据结构扩展性很差，这种选择也是很必要的，因为broker 可以很确切地知道哪些消息已经被消费过，然后可以立即删除它，通过这种方式可以保证数据永远处于最小规模下。

但是上述的这种系统如何保证 broker 和 consumer 在消费位置的一致性是一个棘手的问题。如果 broker 每次在将一个消息发送出去之后立刻将这条消息标记成 **consumed** 状态，那么一旦 consumer 处理这条消息失败了（比如说 consumer 服务崩溃或者超时等），那么这个消息就相当于丢掉了。为了解决这个问题，许多消息系统都支持 ack 机制，也就是说当消息从 broker 发送出去之后，消息仅仅被标记**sent** ，而不是**consumed**，broker 会等到 consumer 返回这条消息的 ack 之后才会将它标记为**consumed**。这种机制可以防止消息丢失，但是却引入了新问题。首先，如果 consumer 处理完这条消息，但是返回 ack 失败了，那么这个消息就有可能被重复消费。其次还有一个和性能相关的问题，现在 broker 必须为每条消息维护多个状态（第一个状态用于防止这条消息对外发送多次，第二个状态用于标记该条消息已经被消费完成，标识它可以被删除掉），同时还会引入很多新的棘手的问题，比如那些已经被发送出去却长时间收不到ack 的消息应该如何处理。

Kafka 在这个问题上的处理模式是不同的。Kafka 的 topic 被划分成一组完全有序的 partition。每个 partition 在任何时候都被每个订阅的 consumer group 的唯一一个 consumer 所消费。这意味着每个 partition 的消费位点就是一个整数而已，就是下一条即将消费的消息位点。这种机制使得存储消费位置的状态非常小，每个 partition 就是一个数字。同时这个状态可以被周期 checkpoint，这使得消息 ack的性能开销也很小。

同时这种机制还有另外一个附加好处，consumer 可以主动倒退到一个旧的 offset 上然后重新消费历史数据。这样做虽然有违消息队列的普遍认知，但是对于一些消费场景来说是一个很必要的功能。比如说，如果 consumer 的代码中有 bug，而且是在已经消费了一些消息之后这个 bug 才被发现，那么这个 consumer 可以在 bug 修复之后重新消费历史消息。

## 离线数据加载

可扩展的数据持久化机制允许一些只会周期性定时拉取数据的 consumer 存在，例如定期将数据批量加载到离线系统（如 Hadoop 或关系型数据仓库）中的批量数据加载操作。

以 Hadoop 为例，我们通过将数据加载行为分散到多个互相独立的 map 任务中来实现并行数据加载，这里的每个 map 任务都是一个 node/topic/partition 的组合。通过这种方式可以实现数据加载过程的完全并行化。Hadoop 提供了任务管理功能，一个任务失败后重启也不会有数据重复处理的风险，因为他们仅仅是从原来的位置重新启动。